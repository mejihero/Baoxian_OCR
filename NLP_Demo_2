"""
Created on Thu Jun 20 15:54:44 2019

@author: luy1
"""

import PyPDF2
import os
from os import listdir
from os.path import isfile, join

from io import StringIO
import pandas as pd

from collections import Counter
import en_core_web_sm
from spacy.matcher import PhraseMatcher

nlp = en_core_web_sm.load()

mypath = '/home/luy1/Desktop/Resume/CVs'

onlyfiles = [os.path.join(mypath, f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]

onlyfiles


from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
from pdfminer.converter import TextConverter
from pdfminer.layout import LAParams
from pdfminer.pdfpage import PDFPage
from io import StringIO
import os

#https://stackoverflow.com/questions/5725278/how-do-i-use-pdfminer-as-a-library/42154976#42154976
#pdf to text


def convert_pdf_to_txt(path, pages = None):
    if not pages:
        pagenums = set()
    else:
        pagenums =set(pages)
    output = StringIO()
    manager = PDFResourceManager()
    converter = TextConverter(manager, output, laparams = LAParams())
    interpreter = PDFPageInterpreter(manager, converter)
    
    infile = open(file, 'rb')
    for page in PDFPage.get_pages(infile, pagenums):
        interpreter.process_page(page)
    infile.close()
    converter.close()
    text = output.getvalue()
    output.close()
    return text

file
convert_pdf_to_txt(file)


def create_profile_2(file):
    #text = pdfextract(file)
    text = convert_pdf_to_txt(file)
    text = str(text)
    text = text.replace("\\n", "")
    text = text.lower()
    
    keyword_dict = pd.read_csv("/home/luy1/Desktop/Resume/template_new.csv", encoding = "ISO-8859-1")
    stats_words = [nlp(text) for text in keyword_dict['Statistics'].dropna(axis = 0)]
    NLP_words = [nlp(text) for text in keyword_dict['NLP'].dropna(axis = 0)]
    ML_words = [nlp(text) for text in keyword_dict['Machine Learning'].dropna(axis = 0)]
    DL_words = [nlp(text) for text in keyword_dict['Deep Learning'].dropna(axis = 0)]
    R_words = [nlp(text) for text in keyword_dict['R Language'].dropna(axis = 0)]
    python_words = [nlp(text) for text in keyword_dict['Python Language'].dropna(axis = 0)]
    Data_Engineering_words = [nlp(text) for text in keyword_dict['Data Engineering'].dropna(axis = 0)]
    
    matcher = PhraseMatcher(nlp.vocab)
    matcher.add('Stats', None, *stats_words)
    matcher.add('NLP', None, *NLP_words)
    matcher.add('ML', None, *ML_words)
    matcher.add('DL', None, *DL_words)
    matcher.add('R', None, *R_words)
    matcher.add('Python', None, *python_words)
    matcher.add('DE', None, *Data_Engineering_words)
    doc = nlp(text)
    
    d = []
    matches = matcher(doc)
    for match_id, start, end in matches:
        rule_id = nlp.vocab.strings[match_id]
        span = doc[start:end]
        d.append((rule_id, span.text))
    keywords = "\n".join(f"{i[0]} {i[1]} ({j})" for i, j in Counter(d).items())
    
    #converting string of keywords to dataframe
    df = pd.read_csv(StringIO(keywords), names = ['Keywords_List'])
    df1 = pd.DataFrame(df.Keywords_List.str.split(' ', 1).tolist(), columns = ['Subject', 'Keyword'])
    df2 = pd.DataFrame(df1.Keyword.str.split('(', 1).tolist(), columns = ['Keyword', 'Count'])
    df3 = pd.concat([df1['Subject'], df2['Keyword'], df2['Count']], axis = 1)
    df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(")"))
    
    base = os.path.basename(file)
    filename = os.path.splitext(base)[0]
    
    name = filename.split('_')
    name2 = name[0]
    name2 = name2.lower()
    
    #converting str to dataframe
    name3 = pd.read_csv(StringIO(name2), names = ['Candidate Name'])
    
    dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)
    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)
    
    return(dataf)


final_database = pd.DataFrame()

i = 0

while i < len(onlyfiles):
    file = onlyfiles[i]
    dat = create_profile_2(file)
    final_database = final_database.append(dat)
    i += 1
    print(final_database)

