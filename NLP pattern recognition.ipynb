{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"C:\\\\Users\\\\LUY1\\\\Desktop\\\\practice\\\\Resume\\\\CVs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [os.path.join(mypath, f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read resumes\n",
    "\n",
    "def pdfextract(file):\n",
    "    fileReader = PyPDF2.PdfFileReader(open(file, 'rb'))\n",
    "    countpage = fileReader.getNumPages()\n",
    "    count = 0\n",
    "    text = []\n",
    "    while count < countpage:\n",
    "        pageObj = fileReader.getPage(count)\n",
    "        count += 1\n",
    "        t = pageObj.extractText()\n",
    "        print(t)\n",
    "        text.append(t)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do phrase matching and build candidate profile\n",
    "\n",
    "def create_profile(file):\n",
    "    text = pdfextract(file)\n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\\\n\", \"\")\n",
    "    text = text.lower()\n",
    "    \n",
    "    keyword_dict = pd.read_csv(\"C:\\\\Users\\\\LUY1\\\\Desktop\\\\practice\\\\Resume\\\\template_new.csv\", encoding = \"ISO-8859-1\")\n",
    "    stats_words = [nlp(text) for text in keyword_dict['Statistics'].dropna(axis = 0)]\n",
    "    NLP_words = [nlp(text) for text in keyword_dict['NLP'].dropna(axis = 0)]\n",
    "    ML_words = [nlp(text) for text in keyword_dict['Machine Learning'].dropna(axis = 0)]\n",
    "    DL_words = [nlp(text) for text in keyword_dict['Deep Learning'].dropna(axis = 0)]\n",
    "    R_words = [nlp(text) for text in keyword_dict['R Language'].dropna(axis = 0)]\n",
    "    python_words = [nlp(text) for text in keyword_dict['Python Language'].dropna(axis = 0)]\n",
    "    Data_Engineering_words = [nlp(text) for text in keyword_dict['Data Engineering'].dropna(axis = 0)]\n",
    "    \n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    matcher.add('Stats', None, *stats_words)\n",
    "    matcher.add('NLP', None, *NLP_words)\n",
    "    matcher.add('ML', None, *ML_words)\n",
    "    matcher.add('DL', None, *DL_words)\n",
    "    matcher.add('R', None, *R_words)\n",
    "    matcher.add('Python', None, *R_words)\n",
    "    matcher.add('DE', None, *Data_Engineering_words)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    d = []\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        rule_id = nlp.vocab.strings[match_id]\n",
    "        span = doc[start:end]\n",
    "        d.append((rule_id, span.text))\n",
    "    keywords = \"\\n\".join(f\"{i[0]} {i[1]} ({j})\" for i, j in Counter(d).items())\n",
    "    \n",
    "    #converting string of keywords to dataframe\n",
    "    df = pd.read_csv(StringIO(keywords), names = ['Keywords_List'])\n",
    "    df1 = pd.DataFrame(df.Keywords_List.str.split(' ', 1).tolist(), columns = ['Subject', 'Keyword'])\n",
    "    df2 = pd.DataFrame(df1.Keyword.str.split('(', 1).tolist(), columns = ['Keyword', 'Count'])\n",
    "    df3 = pd.concat([df1['Subject'], df2['Keyword'], df2['Count']], axis = 1)\n",
    "    df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
    "    \n",
    "    base = os.path.basename(file)\n",
    "    filename = os.path.splitext(base)[0]\n",
    "    \n",
    "    name = filename.split('_')\n",
    "    name2 = name[0]\n",
    "    name2 = name2.lower()\n",
    "    \n",
    "    #converting str to dataframe\n",
    "    name3 = pd.read_csv(StringIO(name2), names = ['Candidate Name'])\n",
    "    \n",
    "    dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
    "    \n",
    "    return(dataf)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_database = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "\n",
    "# while i < len(onlyfiles):\n",
    "#     file = onlyfiles[i]\n",
    "#     dat = create_profile(file)\n",
    "#     final_database = final_database.append(dat)\n",
    "#     i += 1\n",
    "#     print(final_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = onlyfiles[2]\n",
    "# print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat = create_profile(file)\n",
    "# dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = pdfextract(file)\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Machine Learning</th>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>R Language</th>\n",
       "      <th>Python Language</th>\n",
       "      <th>NLP</th>\n",
       "      <th>Data Engineering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>statistical models</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>keras</td>\n",
       "      <td>ggplot</td>\n",
       "      <td>flask</td>\n",
       "      <td>nlp</td>\n",
       "      <td>aws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>statisticalmodeling</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>theano</td>\n",
       "      <td>shiny</td>\n",
       "      <td>django</td>\n",
       "      <td>natural language processing</td>\n",
       "      <td>ec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>probability</td>\n",
       "      <td>K means</td>\n",
       "      <td>face detection</td>\n",
       "      <td>cran</td>\n",
       "      <td>pandas</td>\n",
       "      <td>topic modeling</td>\n",
       "      <td>amazon redshift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal distribution</td>\n",
       "      <td>random forest</td>\n",
       "      <td>neural networks</td>\n",
       "      <td>dplyr</td>\n",
       "      <td>numpy</td>\n",
       "      <td>lda</td>\n",
       "      <td>s3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poisson distribution</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>convolutional neural network (cnn)</td>\n",
       "      <td>tidyr</td>\n",
       "      <td>scikitlearn</td>\n",
       "      <td>named entity recognition</td>\n",
       "      <td>docker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>survival models</td>\n",
       "      <td>Random forest</td>\n",
       "      <td>recureent neural network (RNN)</td>\n",
       "      <td>lubridate</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>pos taging</td>\n",
       "      <td>kubernets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hypothesis testing</td>\n",
       "      <td>naïve bayes</td>\n",
       "      <td>object detction</td>\n",
       "      <td>knitr</td>\n",
       "      <td>matplotlib</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>scala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>factor analysis</td>\n",
       "      <td>pca</td>\n",
       "      <td>yolo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scipy</td>\n",
       "      <td>word embedding</td>\n",
       "      <td>teradata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>forecasting</td>\n",
       "      <td>decision trees</td>\n",
       "      <td>gpu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bokeh</td>\n",
       "      <td>lsi</td>\n",
       "      <td>google big query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>markov chain</td>\n",
       "      <td>svd</td>\n",
       "      <td>cuda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>statsmodel</td>\n",
       "      <td>spacy</td>\n",
       "      <td>aws emr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>monte carlo</td>\n",
       "      <td>ensemble models</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gensim</td>\n",
       "      <td>hive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>boltzman machine</td>\n",
       "      <td>lstm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nltk</td>\n",
       "      <td>hadoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nmf</td>\n",
       "      <td>sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>opencv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cbow</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bag of words</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>skip gram</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentiment analysis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chat bot</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Statistics     Machine Learning  \\\n",
       "0     statistical models    linear regression   \n",
       "1    statisticalmodeling  logistic regression   \n",
       "2            probability              K means   \n",
       "3    normal distribution        random forest   \n",
       "4   poisson distribution              xgboost   \n",
       "5        survival models        Random forest   \n",
       "6     hypothesis testing          naïve bayes   \n",
       "7        factor analysis                  pca   \n",
       "8            forecasting       decision trees   \n",
       "9           markov chain                  svd   \n",
       "10           monte carlo      ensemble models   \n",
       "11                   NaN     boltzman machine   \n",
       "12                   NaN                  NaN   \n",
       "13                   NaN                  NaN   \n",
       "14                   NaN                  NaN   \n",
       "15                   NaN                  NaN   \n",
       "16                   NaN                  NaN   \n",
       "17                   NaN                  NaN   \n",
       "18                   NaN                  NaN   \n",
       "\n",
       "                         Deep Learning R Language Python Language  \\\n",
       "0                                keras     ggplot           flask   \n",
       "1                               theano      shiny          django   \n",
       "2                       face detection       cran          pandas   \n",
       "3                      neural networks      dplyr           numpy   \n",
       "4   convolutional neural network (cnn)      tidyr     scikitlearn   \n",
       "5       recureent neural network (RNN)  lubridate         sklearn   \n",
       "6                      object detction      knitr      matplotlib   \n",
       "7                                 yolo        NaN           scipy   \n",
       "8                                  gpu        NaN           bokeh   \n",
       "9                                 cuda        NaN      statsmodel   \n",
       "10                          tensorflow        NaN             NaN   \n",
       "11                                lstm        NaN             NaN   \n",
       "12                                 gan        NaN             NaN   \n",
       "13                              opencv        NaN             NaN   \n",
       "14                                 NaN        NaN             NaN   \n",
       "15                                 NaN        NaN             NaN   \n",
       "16                                 NaN        NaN             NaN   \n",
       "17                                 NaN        NaN             NaN   \n",
       "18                                 NaN        NaN             NaN   \n",
       "\n",
       "                            NLP  Data Engineering  \n",
       "0                           nlp               aws  \n",
       "1   natural language processing               ec2  \n",
       "2                topic modeling   amazon redshift  \n",
       "3                           lda                s3  \n",
       "4      named entity recognition            docker  \n",
       "5                    pos taging         kubernets  \n",
       "6                      word2vec             scala  \n",
       "7                word embedding          teradata  \n",
       "8                           lsi  google big query  \n",
       "9                         spacy           aws emr  \n",
       "10                       gensim              hive  \n",
       "11                         nltk            hadoop  \n",
       "12                          nmf               sql  \n",
       "13                      doc2vec               NaN  \n",
       "14                         cbow               NaN  \n",
       "15                 bag of words               NaN  \n",
       "16                    skip gram               NaN  \n",
       "17           sentiment analysis               NaN  \n",
       "18                     chat bot               NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_dict = pd.read_csv(\"C:\\\\Users\\\\LUY1\\\\Desktop\\\\practice\\\\Resume\\\\template_new.csv\",\n",
    "                          encoding = \"ISO-8859-1\")\n",
    "keyword_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
